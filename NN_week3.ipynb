{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_week3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjM8pctq+X+uW3iU7eeQ3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halilyaman/basic_neural_network/blob/master/NN_week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXe8pRunGaiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXSoSODaupiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Activations:\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid(X):\n",
        "\n",
        "    return 1 / (1 + np.exp(-X))\n",
        "\n",
        "  @staticmethod\n",
        "  def linear(X):\n",
        "\n",
        "    return X\n",
        "\n",
        "  @staticmethod\n",
        "  def relu(X):\n",
        "\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu(X):\n",
        "\n",
        "    return np.maximum(0.01 * X, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(X):\n",
        "\n",
        "    return np.tanh(X)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_derivative(X):\n",
        "\n",
        "    X_sigmoid = Activations.sigmoid(X)\n",
        "\n",
        "    return X_sigmoid * (1 - X_sigmoid)\n",
        "\n",
        "  @staticmethod\n",
        "  def relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0.01\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_derivative(X):\n",
        "\n",
        "    tanh = Activations.tanh(X)\n",
        "    \n",
        "    return 1 - tanh ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW01W026GtId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "\n",
        "  def __init__(self, units, input_size=0, activation=\"linear\"):\n",
        "\n",
        "    self.units = units\n",
        "    self.input_size = input_size\n",
        "    self.activation = activation\n",
        "    self.layer_type = None\n",
        "    self.predictions = None\n",
        "    self.inputs = None\n",
        "    self.learning_rate = None\n",
        "    self.next_layer = None\n",
        "    self.activation_derivative = None\n",
        "    self.z_1 = None\n",
        "\n",
        "    if input_size > 0:\n",
        "      self.__init_weights()\n",
        "  \n",
        "  def __init_weights(self,):\n",
        "\n",
        "    self.w = np.random.rand(self.units, self.input_size)\n",
        "    self.b = np.random.rand(self.units, 1)\n",
        "\n",
        "  def _forward_prop(self, X):\n",
        "\n",
        "    if X.shape[1] != self.input_size:\n",
        "      raise Exception(\"input shape doesn't match with the data!\")\n",
        "\n",
        "    self.inputs = X\n",
        "\n",
        "    dot_products = np.dot(self.w, X.T)\n",
        "    pred = dot_products + self.b\n",
        "    self.z_1 = pred\n",
        "    pred = self._choose_activation(pred)\n",
        "\n",
        "    self.predictions = pred\n",
        "\n",
        "    return self.predictions.T\n",
        "  \n",
        "  def _backward_prop(self, Y):\n",
        "\n",
        "    avg_factor = (1 / len(self.inputs))\n",
        "\n",
        "    # derivative calculations are different in order to layer type.\n",
        "    # So we need these conditions\n",
        "    if self.layer_type == \"output_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.predictions - Y\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "      \n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "    \n",
        "    if self.layer_type == \"hidden_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.next_layer.w.T.dot(self.next_layer.d_z) * self.activation_derivative(self.z_1)\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "\n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "\n",
        "\n",
        "  def _choose_activation(self, X):\n",
        "\n",
        "    if self.activation == \"sigmoid\":\n",
        "      X = Activations.sigmoid(X)\n",
        "      self.activation_derivative = Activations.sigmoid_derivative\n",
        "    \n",
        "    elif self.activation == \"linear\":\n",
        "      X = Activations.linear(X)\n",
        "    \n",
        "    elif self.activation == \"relu\":\n",
        "      X = Activations.relu(X)\n",
        "      self.activation_derivative = Activations.relu_derivative\n",
        "\n",
        "    elif self.activation == \"leaky_relu\":\n",
        "      X = Activations.leaky_relu(X)\n",
        "      self.activation_derivative = Activations.leaky_relu_derivative\n",
        "\n",
        "    elif self.activation == \"tanh\":\n",
        "      X = Activations.tanh(X)\n",
        "      self.activation_derivative = Activations.tanh_derivative\n",
        "\n",
        "    return X\n",
        "    \n",
        "  def _bind_to(self, layer):\n",
        "\n",
        "    self.input_size = layer.units\n",
        "    self.__init_weights()\n",
        "\n",
        "  def _set_layer_type(self, layer_type):\n",
        "\n",
        "    self.layer_type = layer_type\n",
        "\n",
        "  def _set_learning_rate(self, learning_rate):\n",
        "    \n",
        "    self.learning_rate = learning_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKi5ojI9zXl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel:\n",
        "  \n",
        "  def __init__(self, learning_rate=0.01):\n",
        "\n",
        "    self.layers = list()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.history = dict()\n",
        "\n",
        "\n",
        "  def add_layer(self, layer):\n",
        "\n",
        "    if len(self.layers) == 0:\n",
        "\n",
        "      self.layers.append(layer)\n",
        "      self.layers[0]._set_layer_type(\"output_layer\")\n",
        "\n",
        "    else:\n",
        "\n",
        "      layer._bind_to(self.layers[-1])\n",
        "      self.layers[-1].next_layer = layer\n",
        "      self.layers.append(layer)\n",
        "      \n",
        "\n",
        "      n = len(self.layers)\n",
        "      last_layer_i = n - 1\n",
        "      before_last_i = n - 2\n",
        "\n",
        "      self.layers[last_layer_i]._set_layer_type(\"output_layer\")\n",
        "      self.layers[before_last_i]._set_layer_type(\"hidden_layer\")\n",
        "\n",
        "    self.layers[-1]._set_learning_rate(self.learning_rate)\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, epochs, verbose=True):\n",
        "\n",
        "    self.history[\"loss\"] = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "\n",
        "      if verbose:\n",
        "        print(\"Epoch {}\\n\".format(i+1))\n",
        "  \n",
        "      current_output = X\n",
        "      for j in self.layers:\n",
        "\n",
        "        current_output = j._forward_prop(current_output)\n",
        "      \n",
        "      for j in reversed(range(len(self.layers))):\n",
        "\n",
        "        self.layers[j]._backward_prop(Y)\n",
        "        \n",
        "      \n",
        "      self.history[\"loss\"].append(np.sum(np.abs(Y - current_output)))\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "\n",
        "    current_output = X\n",
        "    for i in self.layers:\n",
        "\n",
        "      current_output = i._forward_prop(current_output)\n",
        "    \n",
        "    return current_output\n",
        "\n",
        "  \n",
        "  def print_layers(self,):\n",
        "    print(\"\\n****************************\\n\")\n",
        "\n",
        "    for i, v in enumerate(self.layers):\n",
        "      print(\"Layer Index: {}\\nLayer Type: {}\\nUnits: {}\\nActivation: {}\\n\"\n",
        "      .format(i, v.layer_type, v.units, v.activation, v.input_size))\n",
        "    \n",
        "    print(\"****************************\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niVW_wLVQ1nj",
        "colab_type": "code",
        "outputId": "3baaf767-c7c9-4895-9d98-b571fae59c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
        "Y = np.array([1, 0, 0, 0])\n",
        "\n",
        "past = time.time()\n",
        "\n",
        "model = MyModel(0.001)\n",
        "\n",
        "layer_1 = Layer(units=10, input_size=2, activation=\"relu\")\n",
        "layer_2 = Layer(units=20, activation=\"relu\")\n",
        "layer_3 = Layer(units=1, activation=\"sigmoid\")\n",
        "\n",
        "model.add_layer(layer_1)\n",
        "model.add_layer(layer_2)\n",
        "model.add_layer(layer_3)\n",
        "\n",
        "before_fit = model.predict(X)\n",
        "model.fit(X, Y, 10000, verbose=False)\n",
        "after_fit = model.predict(X)\n",
        "\n",
        "print(\"Result before fit:\\n\", before_fit)\n",
        "print(\"Result after fit:\\n\", after_fit)\n",
        "print(\"\\nTime passed: \", time.time() - past)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result before fit:\n",
            " [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "Result after fit:\n",
            " [[0.96198743]\n",
            " [0.02731203]\n",
            " [0.03450292]\n",
            " [0.01546721]]\n",
            "\n",
            "Time passed:  2.224144458770752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPH6QVKREPG",
        "colab_type": "code",
        "outputId": "8eefa8fe-bfda-4f97-deb2-1be96b286818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(model.history[\"loss\"])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7f54f180b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u52zJ691_rUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
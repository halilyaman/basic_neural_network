{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_week3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHZckx0Kb9gAfaBSiPLHQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halilyaman/neural_network_implementation/blob/master/NN_week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXe8pRunGaiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXSoSODaupiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Activations:\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid(X):\n",
        "\n",
        "    return 1 / (1 + np.exp(-X))\n",
        "\n",
        "  @staticmethod\n",
        "  def linear(X):\n",
        "\n",
        "    return X\n",
        "\n",
        "  @staticmethod\n",
        "  def relu(X):\n",
        "\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu(X):\n",
        "\n",
        "    return np.maximum(0.01 * X, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(X):\n",
        "\n",
        "    return np.tanh(X)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_derivative(X):\n",
        "\n",
        "    X_sigmoid = Activations.sigmoid(X)\n",
        "\n",
        "    return X_sigmoid * (1 - X_sigmoid)\n",
        "\n",
        "  @staticmethod\n",
        "  def relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0.01\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_derivative(X):\n",
        "\n",
        "    tanh = Activations.tanh(X)\n",
        "    \n",
        "    return 1 - tanh ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW01W026GtId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "\n",
        "  def __init__(self, units, input_size=0, activation=\"linear\"):\n",
        "\n",
        "    self.units = units\n",
        "    self.input_size = input_size\n",
        "    self.activation = activation\n",
        "    self.layer_type = None\n",
        "    self.predictions = None\n",
        "    self.inputs = None\n",
        "    self.learning_rate = None\n",
        "    self.next_layer = None\n",
        "    self.activation_derivative = None\n",
        "    self.z_1 = None\n",
        "\n",
        "    if input_size > 0:\n",
        "      self.__init_weights()\n",
        "  \n",
        "  def __init_weights(self,):\n",
        "\n",
        "    self.w = np.random.rand(self.units, self.input_size) * 0.01\n",
        "    self.b = np.zeros((self.units, 1))\n",
        "\n",
        "  def _forward_prop(self, X):\n",
        "\n",
        "    if X.shape[1] != self.input_size:\n",
        "      raise Exception(\"input shape doesn't match with the data!\")\n",
        "\n",
        "    self.inputs = X\n",
        "\n",
        "    dot_products = np.dot(self.w, X.T)\n",
        "    pred = dot_products + self.b\n",
        "    self.z_1 = pred\n",
        "    pred = self._choose_activation(pred)\n",
        "\n",
        "    self.predictions = pred\n",
        "\n",
        "    return self.predictions.T\n",
        "  \n",
        "  def _backward_prop(self, Y):\n",
        "\n",
        "    avg_factor = (1 / len(self.inputs))\n",
        "\n",
        "    # derivative calculations are different in order to layer type.\n",
        "    # So we need these conditions\n",
        "    if self.layer_type == \"output_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.predictions - Y\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "      \n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "    \n",
        "    if self.layer_type == \"hidden_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.next_layer.w.T.dot(self.next_layer.d_z) * self.activation_derivative(self.z_1)\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "\n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "\n",
        "\n",
        "  def _choose_activation(self, X):\n",
        "\n",
        "    if self.activation == \"sigmoid\":\n",
        "      X = Activations.sigmoid(X)\n",
        "      self.activation_derivative = Activations.sigmoid_derivative\n",
        "    \n",
        "    elif self.activation == \"linear\":\n",
        "      X = Activations.linear(X)\n",
        "    \n",
        "    elif self.activation == \"relu\":\n",
        "      X = Activations.relu(X)\n",
        "      self.activation_derivative = Activations.relu_derivative\n",
        "\n",
        "    elif self.activation == \"leaky_relu\":\n",
        "      X = Activations.leaky_relu(X)\n",
        "      self.activation_derivative = Activations.leaky_relu_derivative\n",
        "\n",
        "    elif self.activation == \"tanh\":\n",
        "      X = Activations.tanh(X)\n",
        "      self.activation_derivative = Activations.tanh_derivative\n",
        "\n",
        "    return X\n",
        "    \n",
        "  def _bind_to(self, layer):\n",
        "\n",
        "    self.input_size = layer.units\n",
        "    self.__init_weights()\n",
        "\n",
        "  def _set_layer_type(self, layer_type):\n",
        "\n",
        "    self.layer_type = layer_type\n",
        "\n",
        "  def _set_learning_rate(self, learning_rate):\n",
        "    \n",
        "    self.learning_rate = learning_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKi5ojI9zXl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel:\n",
        "  \n",
        "  def __init__(self, learning_rate=0.01):\n",
        "\n",
        "    self.layers = list()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.history = dict()\n",
        "\n",
        "\n",
        "  def add_layer(self, layer):\n",
        "\n",
        "    if len(self.layers) == 0:\n",
        "\n",
        "      self.layers.append(layer)\n",
        "      self.layers[0]._set_layer_type(\"output_layer\")\n",
        "\n",
        "    else:\n",
        "\n",
        "      layer._bind_to(self.layers[-1])\n",
        "      self.layers[-1].next_layer = layer\n",
        "      self.layers.append(layer)\n",
        "      \n",
        "\n",
        "      n = len(self.layers)\n",
        "      last_layer_i = n - 1\n",
        "      before_last_i = n - 2\n",
        "\n",
        "      self.layers[last_layer_i]._set_layer_type(\"output_layer\")\n",
        "      self.layers[before_last_i]._set_layer_type(\"hidden_layer\")\n",
        "\n",
        "    self.layers[-1]._set_learning_rate(self.learning_rate)\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, epochs, verbose=True):\n",
        "\n",
        "    self.history[\"loss\"] = []\n",
        "    m = len(Y)\n",
        "\n",
        "    for i in range(epochs):\n",
        "\n",
        "      if verbose:\n",
        "        print(\"Epoch {}\\n\".format(i+1))\n",
        "  \n",
        "      current_output = X\n",
        "      for j in self.layers:\n",
        "\n",
        "        current_output = j._forward_prop(current_output)\n",
        "      \n",
        "      for j in reversed(range(len(self.layers))):\n",
        "\n",
        "        self.layers[j]._backward_prop(Y)\n",
        "      \n",
        "      logprobs = np.multiply(np.log(current_output.flatten()), Y) + np.multiply(np.log(1-current_output.flatten()), (1-Y))\n",
        "      cost = - np.sum(logprobs) / m\n",
        "      \n",
        "      self.history[\"loss\"].append(cost)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "\n",
        "    current_output = X\n",
        "    for i in self.layers:\n",
        "\n",
        "      current_output = i._forward_prop(current_output)\n",
        "    \n",
        "    return current_output\n",
        "\n",
        "  \n",
        "  def print_layers(self,):\n",
        "    print(\"\\n****************************\\n\")\n",
        "\n",
        "    for i, v in enumerate(self.layers):\n",
        "      print(\"Layer Index: {}\\nLayer Type: {}\\nUnits: {}\\nActivation: {}\\n\"\n",
        "      .format(i, v.layer_type, v.units, v.activation, v.input_size))\n",
        "    \n",
        "    print(\"****************************\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niVW_wLVQ1nj",
        "colab_type": "code",
        "outputId": "f1b534cf-8b9b-4f56-a040-311deeebb1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
        "Y = np.array([1, 0, 0, 0])\n",
        "\n",
        "past = time.time()\n",
        "\n",
        "model = MyModel(0.1)\n",
        "\n",
        "layer_1 = Layer(units=4, input_size=2, activation=\"tanh\")\n",
        "layer_2 = Layer(units=1, activation=\"sigmoid\")\n",
        "\n",
        "model.add_layer(layer_1)\n",
        "model.add_layer(layer_2)\n",
        "\n",
        "before_fit = model.predict(X)\n",
        "model.fit(X, Y, 2000, verbose=False)\n",
        "after_fit = model.predict(X)\n",
        "\n",
        "print(\"Results before fitting:\\n\", before_fit)\n",
        "print(\"Results after fitting:\\n\", after_fit)\n",
        "print(\"\\nTime passed: \", time.time() - past)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results before fitting:\n",
            " [[0.5000654 ]\n",
            " [0.50002562]\n",
            " [0.50003978]\n",
            " [0.5       ]]\n",
            "Results after fitting:\n",
            " [[9.91032384e-01]\n",
            " [4.50700359e-03]\n",
            " [4.50324222e-03]\n",
            " [2.94596679e-05]]\n",
            "\n",
            "Time passed:  0.15378785133361816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPH6QVKREPG",
        "colab_type": "code",
        "outputId": "d83b9015-424b-4777-f7fb-c68aea850d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(model.history[\"loss\"])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f64cd86dac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXRc9X338fd3ZrTasrV6k2TLBmEw2IBRwCVAoZBgoDVJyGKe9GRpEp60ddOkTxdy8pQnh65JnibnySknCSEp2Qkhm5M4dQlZgIKJZWOMVyzvu+VVlmXt3+ePuVbGQrJG8szcmdHndc6cufd3f5r79ZX80dXvbubuiIhI7ouEXYCIiKSGAl1EJE8o0EVE8oQCXUQkTyjQRUTyRCysFVdXV3tDQ0NYqxcRyUlr1qw56u41Qy0LLdAbGhpobm4Oa/UiIjnJzHYPt0xDLiIieUKBLiKSJxToIiJ5IqlAN7PFZrbVzFrM7MEhln/OzNYFr9fM7GTqSxURkQsZ8aComUWBR4A3AfuA1Wa23N03nevj7h9L6P8XwLVpqFVERC4gmT3064EWd9/h7t3AE8C9F+h/P/CdVBQnIiLJSybQa4G9CfP7grbXMbNZwGzgl8Msf8DMms2subW1dbS1iojIBaT6oOhS4Cl37xtqobs/6u5N7t5UUzPkefEjWr3rOJ/6zy3otr8iIudLJtD3A/UJ83VB21CWkubhllf2nuQLv97OyY6edK5GRCTnJBPoq4FGM5ttZoXEQ3v54E5mdjlQAbyY2hLPN2VSMQCt7V3pXI2ISM4ZMdDdvRdYBqwENgNPuvtGM3vYzJYkdF0KPOFpHguZUlYEwJE2BbqISKKk7uXi7iuAFYPaHho0/8nUlTW8gUA/3ZmJ1YmI5Iycu1L03JDLkdPaQxcRSZRzgT6xKEZpYVRDLiIig+RcoEN82EVDLiIi58vJQK8pK9KQi4jIIDkZ6FPKimlVoIuInCc3A31SEYfbOnW1qIhIgpwM9NryEjq6+3S1qIhIgpwM9JmVpQDsOd4RciUiItkjJwO9XoEuIvI6OR3oe08o0EVEzsnJQJ9YFKNqQiF7tYcuIjIgJwMdoK6ylL3Hz4ZdhohI1sjZQJ9ZWcquY2fCLkNEJGvkbKBfNmUi+06cpb2rN+xSRESyQs4G+txpZQC8dvh0yJWIiGSHnA30K6ZPAmDrIQW6iAjkcKDXlpcwoTDKloNtYZciIpIVcjbQIxFj7rQyNh/UHrqICORwoANcXV/O+v0n6e7tD7sUEZHQ5XSgX99QSWdPPxsOnAq7FBGR0CUV6Ga22My2mlmLmT04TJ93mtkmM9toZt9ObZlDa2qoBGD1zuOZWJ2ISFYbMdDNLAo8AtwFzAPuN7N5g/o0Ah8H3ujuVwIfTUOtr1NTVsTs6gm8uONYJlYnIpLVktlDvx5ocfcd7t4NPAHcO6jPh4BH3P0EgLsfSW2Zw7tt7hReaDmmC4xEZNxLJtBrgb0J8/uCtkSXAZeZ2X+b2SozWzzUB5nZA2bWbGbNra2tY6t4kDuvnEp3Xz+/3pqx3yEiIlkpVQdFY0AjcCtwP/BlMysf3MndH3X3JndvqqmpScmKmxoqqZ5YyI/XHUjJ54mI5KpkAn0/UJ8wXxe0JdoHLHf3HnffCbxGPODTLhox3tFUzzObD7P/pO6+KCLjVzKBvhpoNLPZZlYILAWWD+rzI+J755hZNfEhmB0prPOC3n3DTAC++vzOTK1SRCTrjBjo7t4LLANWApuBJ919o5k9bGZLgm4rgWNmtgn4FfA37p6xU0/qKkq5b2Ed33hxN3uO6aEXIjI+mbuHsuKmpiZvbm5O2ecdOtXJ7f/2a+bNmMR3PrSIWDSnr5kSERmSma1x96ahluVN6k2bXMw/vXU+q3ed4KHlG+nvD+cXlYhIWGJhF5BKb7m2li2HTvPF32znZEc3//LWBUwuLQi7LBGRjMirQAf4u8VzqSgt4DMrt7Jqx6/54M2zuW9hHVMnFYddmohIWuXNGPpgG/af4tMrt/Lsa62YwfzayVxbX86VMyYzs6qU+spSpk0qJhqxtNUgIpJqFxpDz9tAP6flSDs/W3+QF7Yf5dX9p+jo7htYFosYM8pLqK8soa68NP5eUcqcmglcMX0SBTqwKiJZZlwHeqK+fmfv8Q72nuhg7/Gz7D3Rwb4TZ9l7PP5+tL1roG9xQYRr6su588pp3DN/OlM0ZCMiWUCBnqSz3X3sP9nBlkOnWbv7JC9sP8qWQ6eJRYy3Laxl2W2NzKwqDbtMERnHFOgXoeVIO99ctZvv/HYPZvA3d17O+29sIKKxdxEJwbg4Dz1dLp0ykU8uuZLf/M1tvPGSav7hp5tY9p21dPb0jfzFIiIZpEBP0rTJxTz23iY+cfcV/HzDIf7k8dUKdRHJKgr0UTAzPnTLHP7v26/mhe3H+Nh31+mKVBHJGgr0MbjvurqBPfVHn8vYTSVFRC5IgT5GH7x5NnfPn8ZnVm7l5T0nwi5HRESBPlZmxr/et4ApZUV8/Aev0tvXH3ZJIjLOKdAvwqTiAv7PH13JlkOnefyFXWGXIyLjnAL9It155VRunVvD55/ZxqmzPWGXIyLjmAL9IpkZf3vn5bR19vLlZ3WAVETCo0BPgXkzJnHPgul89b93cizhfjAiIpmkQE+Rj93RSEd3H99YtTvsUkRknFKgp8ilU8r4g8un8I0Xd+sKUhEJRVKBbmaLzWyrmbWY2YNDLH+fmbWa2brg9cHUl5r9PnDTbI6d6Wb5ugNhlyIi49CIgW5mUeAR4C5gHnC/mc0bout33f2a4PVYiuvMCTdeUsXl08r4jxd2EdZdLEVk/EpmD/16oMXdd7h7N/AEcG96y8pNZsa7b5jJ5oNtbDzQFnY5IjLOJBPotcDehPl9Qdtg95nZejN7yszqh/ogM3vAzJrNrLm1tXUM5Wa/JdfUUhSL8GTz3pE7i4ikUKoOiv4EaHD3BcDTwNeG6uTuj7p7k7s31dTUpGjV2WVySQGLr5rGj17er4OjIpJRyQT6fiBxj7suaBvg7sfc/dwJ2I8B16WmvNz0zqZ62jp7WbnxUNiliMg4kkygrwYazWy2mRUCS4HliR3MbHrC7BJgc+pKzD2/N6eKaZOK+ckrB8MuRUTGkRED3d17gWXASuJB/aS7bzSzh81sSdDtI2a20cxeAT4CvC9dBeeCSMS4e/50nn2tlbZO3d9FRDIjqTF0d1/h7pe5+yXu/k9B20PuvjyY/ri7X+nuV7v7be6+JZ1F54I/vHo63X39/GLT4bBLEZFxQleKpsm19eXUlpfw0/UadhGRzFCgp4mZcff8aTy3rZVTHRp2EZH0U6Cn0T0LZtDT5zyzRcMuIpJ+CvQ0WlA7mZqyIp7ZciTsUkRkHFCgp1EkYvzB3Ck8u7WV7l49c1RE0kuBnma3XzGF0129NO86HnYpIpLnFOhpdlNjNYWxCL/YrGEXEUkvBXqalRbGuPGSKp7Zcli31BWRtFKgZ8DtV0xl97EOtre2h12KiOQxBXoG3DY3fmfJ37x2NORKRCSfKdAzoK6ilNnVE3h+W37eA15EsoMCPUNuurSal3Ye1+mLIpI2CvQMubmxmo7uPtbuORF2KSKSpxToGbLokiqiEeP5bRpHF5H0UKBnyKTiAq6pL+c5jaOLSJoo0DPopkurWb//FCc7usMuRUTykAI9g25urMYdXth+LOxSRCQPKdAz6Or6ciYWxXi+RePoIpJ6CvQMKohGeENDBS/t0B66iKReUoFuZovNbKuZtZjZgxfod5+ZuZk1pa7E/LJoThXbW89w5HRn2KWISJ4ZMdDNLAo8AtwFzAPuN7N5Q/QrA/4SeCnVReaTRXOqAHhph26nKyKplcwe+vVAi7vvcPdu4Ang3iH6/QPwKUC7nhdw5YxJTCyKsUrDLiKSYskEei2wN2F+X9A2wMwWAvXu/rMLfZCZPWBmzWbW3No6Ps/HjgXj6Ap0EUm1iz4oamYR4LPA/xqpr7s/6u5N7t5UU1NzsavOWRpHF5F0SCbQ9wP1CfN1Qds5ZcBVwK/NbBewCFiuA6PD0zi6iKRDMoG+Gmg0s9lmVggsBZafW+jup9y92t0b3L0BWAUscffmtFScBzSOLiLpMGKgu3svsAxYCWwGnnT3jWb2sJktSXeB+SgWjdDUUMFLO7WHLiKpE0umk7uvAFYMantomL63XnxZ+W/RnCr+9edbaD3dRU1ZUdjliEge0JWiIRkYR9+pYRcRSQ0FekiuCsbRX9SNukQkRRToIYlFI1w3S+PoIpI6CvQQ3TCnkpYj7Rxt7wq7FBHJAwr0EJ0bR/+t9tJFJAUU6CGaXzuZ0sKobqcrIimhQA9RQTCOvkpXjIpICijQQ3bD7Eq2Hj7N8TN6zqiIXBwFesg0ji4iqaJAD9mCunKKCyK6wEhELpoCPWSFsQgLZ2ocXUQungI9C9wwu4oth9o41dETdikiksMU6Flg0ZxK3OG3u7SXLiJjp0DPAlfXl1MYi+h8dBG5KAr0LFBcEOXa+nJW6cCoiFwEBXqWuGFOFZsOtNHWqXF0ERkbBXqWWDSnkn6HZo2ji8gYKdCzxMKZFRRGIzp9UUTGTIGeJYoLolxdP1kHRkVkzBToWeSG2VVsONBGe1dv2KWISA5KKtDNbLGZbTWzFjN7cIjlHzazV81snZk9b2bzUl9q/ls0p4q+ftc4uoiMyYiBbmZR4BHgLmAecP8Qgf1td5/v7tcAnwY+m/JKx4GFs8qJRUzj6CIyJsnsoV8PtLj7DnfvBp4A7k3s4O5tCbMTAE9dieNHaWGMBXWTdaMuERmTZAK9FtibML8vaDuPmf25mW0nvof+kaE+yMweMLNmM2tubW0dS71574Y5Vby67xQd3RpHF5HRSdlBUXd/xN0vAf4O+N/D9HnU3ZvcvammpiZVq84ri+ZU0dvvrNl9IuxSRCTHJBPo+4H6hPm6oG04TwBvuZiixrPrZlUQjRirdPqiiIxSMoG+Gmg0s9lmVggsBZYndjCzxoTZe4BtqStxfJlYFOOq2sm8pAOjIjJKIwa6u/cCy4CVwGbgSXffaGYPm9mSoNsyM9toZuuAvwLem7aKx4FFsyt5Zd9Jznb3hV2KiOSQWDKd3H0FsGJQ20MJ03+Z4rrGtUVzqvjSsztYu+cEb7y0OuxyRCRH6ErRLPSG2ZXEIsZz246GXYqI5BAFehaaWBRj4awKntumUztFJHkK9Cx1S2M1Gw+0cay9K+xSRCRHKNCz1M2N8fP0n2/RsIuIJEeBnqWuqp1MeWmBxtFFJGkK9CwVjRhvvLSa57a14q5b44jIyBToWeyWxmoOt3Wx7Uh72KWISA5QoGexm4Jx9Gdf09kuIjIyBXoWqy0v4ZKaCRpHF5GkKNCz3M2NNby08xidPboNgIhcmAI9y906t4bOnn5e3K67L4rIhSnQs9yiOVWUFkb5xebDYZciIllOgZ7ligui3NxYzS+3HNHpiyJyQQr0HHD7FVM5eKqTjQfaRu4sIuOWAj0H/MHlUzCDZzYfCbsUEcliCvQcUD2xiGvqy3lmi8bRRWR4CvQccccVU1m/7xSH2zrDLkVEspQCPUfcfsUUQMMuIjI8BXqOmDu1jFlVpfx8w8GwSxGRLKVAzxFmxj3zp/PC9mMcP9MddjkikoWSCnQzW2xmW82sxcweHGL5X5nZJjNbb2bPmNms1Jcq9yyYTl+/s3LjobBLEZEsNGKgm1kUeAS4C5gH3G9m8wZ1exlocvcFwFPAp1NdqMC86ZNoqCplxasadhGR10tmD/16oMXdd7h7N/AEcG9iB3f/lbt3BLOrgLrUlikQDLssiA+76FmjIjJYMoFeC+xNmN8XtA3nA8DPh1pgZg+YWbOZNbe26h7fY3HP/BnBsIvOSReR86X0oKiZ/THQBHxmqOXu/qi7N7l7U01NTSpXPW5cMb2MOdUT+MkrB8IuRUSyTDKBvh+oT5ivC9rOY2Z3AJ8Alri7xgPSxMy495paVu08xr4THSN/gYiMG8kE+mqg0cxmm1khsBRYntjBzK4FvkQ8zHXlS5q9bWEt7vDDta/7vSoi49iIge7uvcAyYCWwGXjS3Tea2cNmtiTo9hlgIvA9M1tnZsuH+ThJgfrKUhbNqeT7a/fplroiMiCWTCd3XwGsGNT2UML0HSmuS0bw9uvq+evvvcKa3SdoaqgMuxwRyQK6UjRH3XXVNEoLozy1Zl/YpYhIllCg56gJRTHunj+dn7xygNOdPWGXIyJZQIGew/540SzOdPfxw5d1cFREFOg57Zr6chbUTebrL+7WwVERUaDnuvf8XgMtR9p5ccexsEsRkZAp0HPcHy6YTkVpAV9/YXfYpYhIyBToOa64IMq73jCT/9p0iD3HdOWoyHimQM8D739jA7FIhEef2x52KSISIgV6Hpg6qZj7rqvjyeZ9HDmth0iLjFcK9Dzx4d+fQ29fP195fmfYpYhISBToeWJW1QTuWTCDb764mxN65qjIuKRAzyPLbruUjp4+vvAbjaWLjEcK9Dwyd1oZ9y2s4/EXdrH/5NmwyxGRDFOg55mPvekyAD739GshVyIimaZAzzO15SW878YGvr92H5sPtoVdjohkkAI9D/3ZrZdQUVrI3/9oA/39useLyHihQM9D5aWFPHjX5TTvPqH7pYuMIwr0PPX2hXW8oaGCf/n5Zo7rNEaRcUGBnqciEeMf3zKf0529PPTjDbq9rsg4kFSgm9liM9tqZi1m9uAQy28xs7Vm1mtmb099mTIWc6eV8dE7Gvnp+oP8eN2BsMsRkTQbMdDNLAo8AtwFzAPuN7N5g7rtAd4HfDvVBcrF+fDvX8J1syr4+x9v0LnpInkumT3064EWd9/h7t3AE8C9iR3cfZe7rwf601CjXIRYNMLn3nkN/f3Osm+vpau3L+ySRCRNkgn0WmBvwvy+oE1yxMyqUj7zjqt5ec9JPrl8U9jliEiaZPSgqJk9YGbNZtbc2tqayVWPe3fPn86f3noJ3/ntHr71kp5uJJKPkgn0/UB9wnxd0DZq7v6ouze5e1NNTc1YPkIuwl+/eS63zq3h73+0gac3HQ67HBFJsWQCfTXQaGazzawQWAosT29Zkg7RiPHI/1jI/Lpyln17Lb/deTzskkQkhUYMdHfvBZYBK4HNwJPuvtHMHjazJQBm9gYz2we8A/iSmW1MZ9EydhOKYvzH+95AbUUJH3h8NWt2K9RF8oWFdcFJU1OTNzc3h7JugQMnz/Lux17icFsnj72niRsvrQ67JBFJgpmtcfemoZbpStFxakZ5Cd/9n4uoqyjh/Y+vZsWrB8MuSUQukgJ9HJtSVswTD/weV9VO5s++tZbPP7NNtwgQyWEK9HGuckIh3/rgDbzt2lo++/Rr/Nm31nKqoyfsskRkDBToQnFBlH9759V84u4reHrTYe7+/HOs3qWDpSK5RoEuAJgZH7plDk/96Y3Eosa7vvQi//DTTZzp6g27NBFJkgJdznNNfTk/+8jNLL1+Jl95fid3fPY3/OeGQxpbF8kBCnR5nYlFMf75rfP5/p/eyOSSAj78zTW844svahhGJMsp0GVY182q4Cd/cRP/+Jar2H28g3d88UX+5PHVrN51XHvsIllIFxZJUjq6e/mP/97Fl5/bwcmOHq6dWc6Hbp7Dm+ZNpSCq/QKRTLnQhUUKdBmVju5enlqzj8ee28me4x3UlBXxtoW1vLOpnktqJoZdnkjeU6BLyvX1O7/ccoTvrt7Lr7Yeoa/fuaa+nLvnT+Ouq6ZTX1kadokieUmBLml1pK2TH7y8n5+uP8CG/W0AXDljEm+aN5WbG6u5uq6cmIZlRFJCgS4Zs/d4B/+54RArNhxk3d6TuENZUYwb5lRx06VVNDVUcvm0MgW8yBgp0CUUJzu6eWH7MZ7bdpTnW1rZezz+kOqSgigL6iazcFYF19aXM2/GJGrLSzCzkCsWyX4KdMkK+050sHbPSdbuPsHLe06w8UAbvf3xn7+yohiXTy/jiumTuHzaJC6bOpGG6glUTShU0IskuFCgxzJdjIxfdRWl1FWUsuTqGQB09vSx8UAbWw61sflgG1sOnuYHa/fT3vW7Z56WFceYXT2BhqoJNFRPYHZ1/DOmTy5m6qRinTIpkkCBLqEpLohy3awKrptVMdDm7uw7cZaWI+3sPHqGXcfOsPPoGdbuOcFP1h8g8Q/KiMVvATyjvJjp5SXUlpcwdVIx1RMLqZlYRHVZEdUTiygvKSAS0V6+5D8FumQVM6O+spT6ylJuG7Ssq7ePvcc72H+yk4Mnz3Lg5FkOnOrkwMmzbDrQxtObDtPd2/+6z4xFjKqJhVRPjAd81cRCyksKmVxSQHlpAZNLCpgcvJeXFFBeWsik4pgO3ErOUaBLziiKRbl0ShmXTikbcrm7c7Kjh6PtXbS2d3G0vZujp7s42n7u1c3R9i5ajrRz6mwP7SPcSbKsKMakkgImFEWZUBRjYlGMCYUxJhYH04PaB6aLopQWxiguiFBSEKWoIEpJQZSCqOl4gKSVAl3yhplRMaGQigmFNE4dOvQT9fT103a2h5Nnezh1todTHfH3kx3dnDrby8mz3bSd7eVMVy/tXb2c7uzl0KnOgfkz3X309Sd/UkHE4mf4FA+8IpQURimORePvQXtJQYSiWJTCWCT+ip7/XnBufqDNKIxGg2VGYSxCUWK/hK8riEaIavgpbyUV6Ga2GPh/QBR4zN3/ddDyIuDrwHXAMeBd7r4rtaWKpFZBNELVxCKqJhaN6evdna7eftq7emnvDEK+q5cz3b2c7e6ns6ePsz19dA68+gfmz/b00ZUw397Vy9H27oG+Z3v66Ontp7uvn56+1J6JZhYfhopFIsSiFp+ORoJ3oyASD/2h237XvyBqRCMRCiI20D/eZgO/OKJmRIL3aISEaSNy7j1xedB23nJjiL6W0Ddh+RBfH6+B8+qJWPxzzX73+REzbGCagflc+qtqxEA3syjwCPAmYB+w2syWu/umhG4fAE64+6VmthT4FPCudBQski3MbGCvunqMvxSS0d/v9PT3090bf/X0eXy6r4+uxPnefnr6+uk694sgeD+3rLuvn94+p7e/n95+p7fv3HvQ1ufx+WBZT5/T139+n87e+HRPXz995/oGXzvQv+937X39zij+iMlKiSE/8i+AxOVB/8jr+3/k9saBs71SKZk99OuBFnffEf/H2RPAvUBioN8LfDKYfgr4dzMz1z1WRS5aJGIURaIUxaJhlzIm7vFQj4e709fv9LnT3584zRBt8fe+fseDrx/t18XXx+va3KE/qCteX3x6YFl/4vzvpoftn9DmQV0X6l9eUpCWbZ1MoNcCexPm9wE3DNfH3XvN7BRQBRxN7GRmDwAPAMycOXOMJYtILjEzoobG7jMgo+dlufuj7t7k7k01NTWZXLWISN5LJtD3A/UJ83VB25B9zCwGTCZ+cFRERDIkmUBfDTSa2WwzKwSWAssH9VkOvDeYfjvwS42fi4hk1ohj6MGY+DJgJfHTFr/q7hvN7GGg2d2XA18BvmFmLcBx4qEvIiIZlNR56O6+AlgxqO2hhOlO4B2pLU1EREZDN6sQEckTCnQRkTyhQBcRyROhPbHIzFqB3SN2HFo1gy5ayhKqa3SytS7I3tpU1+jkY12z3H3IC3lCC/SLYWbNwz2CKUyqa3SytS7I3tpU1+iMt7o05CIikicU6CIieSJXA/3RsAsYhuoanWytC7K3NtU1OuOqrpwcQxcRkdfL1T10EREZRIEuIpInci7QzWyxmW01sxYzezDD6643s1+Z2SYz22hmfxm0f9LM9pvZuuB1d8LXfDyodauZ3ZnG2naZ2avB+puDtkoze9rMtgXvFUG7mdnng7rWm9nCNNU0N2GbrDOzNjP7aBjby8y+amZHzGxDQtuot4+ZvTfov83M3jvUulJQ12fMbEuw7h+aWXnQ3mBmZxO22xcTvua64PvfEtR+UU+TGKauUX/fUv3/dZi6vptQ0y4zWxe0Z3J7DZcNmf0Z8+ARS7nwIn63x+3AHKAQeAWYl8H1TwcWBtNlwGvAPOKP3/vrIfrPC2osAmYHtUfTVNsuoHpQ26eBB4PpB4FPBdN3Az8HDFgEvJSh790hYFYY2wu4BVgIbBjr9gEqgR3Be0UwXZGGut4MxILpTyXU1ZDYb9Dn/Dao1YLa70pDXaP6vqXj/+tQdQ1a/m/AQyFsr+GyIaM/Y7m2hz7wfFN37wbOPd80I9z9oLuvDaZPA5uJP35vOPcCT7h7l7vvBFqI/xsy5V7ga8H014C3JLR/3eNWAeVmNj3NtdwObHf3C10dnLbt5e7PEr+18+D1jWb73Ak87e7H3f0E8DSwONV1uft/uXtvMLuK+ENlhhXUNsndV3k8Fb6e8G9JWV0XMNz3LeX/Xy9UV7CX/U7gOxf6jDRtr+GyIaM/Y7kW6EM93/RCgZo2ZtYAXAu8FDQtC/50+uq5P6vIbL0O/JeZrbH4s1sBprr7wWD6EDA1hLrOWcr5/9HC3l4w+u0Txnb7E+J7cufMNrOXzew3ZnZz0FYb1JKJukbzfcv09roZOOzu2xLaMr69BmVDRn/Gci3Qs4KZTQS+D3zU3duALwCXANcAB4n/2ZdpN7n7QuAu4M/N7JbEhcGeSCjnqFr8SVdLgO8FTdmwvc4T5vYZjpl9AugFvhU0HQRmuvu1wF8B3zazSRksKeu+b4Pcz/k7DRnfXkNkw4BM/IzlWqAn83zTtDKzAuLfsG+5+w8A3P2wu/e5ez/wZX43TJCxet19f/B+BPhhUMPhc0MpwfuRTNcVuAtY6+6HgxpD316B0W6fjNVnZu8D/hB4dxAEBEMax4LpNcTHpy8LakgclklLXWP4vmVye8WAtwHfTag3o9trqGwgwz9juRboyTzfNG2CMbqvAJvd/bMJ7Ynjz28Fzh2BXw4sNbMiM5sNNBI/GJPquiaYWdm5aeIH1TZw/rNe3wv8OKGu9wRH2hcBpxL+LEyH8/acwt5eCUa7fVYCbzazimC44c1BW0qZ2WLgb4El7t6R0F5jZtFgeg7x7bMjqK3NzBYFP6PvSfi3pLKu0X7fMvn/9Q5gi7sPDKVkcnsNlw1k+mfsYo7shvEifnT4NT+er3MAAADbSURBVOK/bT+R4XXfRPxPpvXAuuB1N/AN4NWgfTkwPeFrPhHUupWLPJJ+gbrmED+D4BVg47ntAlQBzwDbgF8AlUG7AY8Edb0KNKVxm00AjgGTE9oyvr2I/0I5CPQQH5f8wFi2D/Ex7Zbg9f401dVCfBz13M/YF4O+9wXf33XAWuCPEj6niXjAbgf+neAq8BTXNervW6r/vw5VV9D+OPDhQX0zub2Gy4aM/ozp0n8RkTyRa0MuIiIyDAW6iEieUKCLiOQJBbqISJ5QoIuI5AkFuohInlCgi4jkif8PwMOwRwvxFuIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MrC_96GCF82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
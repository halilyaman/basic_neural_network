{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_architecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPoAHJQ6GPmDC0jQVMup4vw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halilyaman/neural_network_implementation/blob/master/NN_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1WJ5oHSamXo",
        "colab_type": "text"
      },
      "source": [
        "#### **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXe8pRunGaiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDKslBsRaxmw",
        "colab_type": "text"
      },
      "source": [
        "# **Activations class**\n",
        "This class contains activation functions and derivatives of them. All functions are static in order to use them directly in a neural network. \\\n",
        "X represents the input matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXSoSODaupiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Activations:\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid(X):\n",
        "\n",
        "    return 1 / (1 + np.exp(-X))\n",
        "\n",
        "  @staticmethod\n",
        "  def linear(X):\n",
        "\n",
        "    return X\n",
        "\n",
        "  @staticmethod\n",
        "  def relu(X):\n",
        "\n",
        "    return np.maximum(0, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu(X):\n",
        "\n",
        "    return np.maximum(0.01 * X, X)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(X):\n",
        "\n",
        "    return np.tanh(X)\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid_derivative(X):\n",
        "\n",
        "    X_sigmoid = Activations.sigmoid(X)\n",
        "\n",
        "    return X_sigmoid * (1 - X_sigmoid)\n",
        "\n",
        "  @staticmethod\n",
        "  def relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu_derivative(X):\n",
        "    \n",
        "    derivatives = np.zeros(X.shape)\n",
        "\n",
        "    for i, rows in enumerate(X):\n",
        "\n",
        "      for j, v in enumerate(rows):\n",
        "\n",
        "        if v < 0:\n",
        "          derivatives[i, j] = 0.01\n",
        "        else:\n",
        "          derivatives[i, j] = 1\n",
        "\n",
        "    return derivatives\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh_derivative(X):\n",
        "\n",
        "    tanh = Activations.tanh(X)\n",
        "    \n",
        "    return 1 - tanh ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1xfiWQjcLJ_",
        "colab_type": "text"
      },
      "source": [
        "# **Layer class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW01W026GtId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer:\n",
        "\n",
        "  def __init__(self, units, input_shape=None, activation=\"linear\"):\n",
        "\n",
        "    self.units = units\n",
        "    self.input_shape = input_shape\n",
        "    self.activation = activation\n",
        "    self.layer_type = None\n",
        "    self.predictions = None\n",
        "    self.inputs = None\n",
        "    self.learning_rate = None\n",
        "    self.next_layer = None\n",
        "    self.activation_derivative = None\n",
        "    self.z_1 = None\n",
        "\n",
        "    if not(self.input_shape == None):\n",
        "      self.__init_weights()\n",
        "  \n",
        "  def __init_weights(self,):\n",
        "\n",
        "    self.w = np.random.rand(self.units, self.input_shape[0])\n",
        "    self.b = np.zeros((self.units, 1))\n",
        "\n",
        "  def _forward_prop(self, X):\n",
        "\n",
        "    if X.shape[0] != self.input_shape[0]:\n",
        "      raise Exception(\"input shape doesn't match with the data!\")\n",
        "\n",
        "    self.inputs = X\n",
        "\n",
        "    dot_products = np.dot(self.w, X)\n",
        "    pred = dot_products + self.b\n",
        "    self.z_1 = pred\n",
        "    self.predictions = self._choose_activation(pred)\n",
        "\n",
        "    return self.predictions\n",
        "  \n",
        "  def _backward_prop(self, Y):\n",
        "\n",
        "    avg_factor = (1 / len(self.inputs))\n",
        "\n",
        "    # derivative calculations are different in order to layer type.\n",
        "    # So we need these conditions\n",
        "    if self.layer_type == \"output_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.predictions - Y\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs.T)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "      \n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "    \n",
        "    if self.layer_type == \"hidden_layer\":\n",
        "\n",
        "      # calculating new weights and b values\n",
        "      self.d_z = self.next_layer.w.T.dot(self.next_layer.d_z) * self.activation_derivative(self.z_1)\n",
        "      d_w = avg_factor * self.d_z.dot(self.inputs.T)\n",
        "      d_b = avg_factor * np.sum(self.d_z, axis=1, keepdims=True)\n",
        "\n",
        "      # updating weights and b\n",
        "      self.b = self.b - self.learning_rate * d_b\n",
        "      self.w = self.w - self.learning_rate * d_w\n",
        "\n",
        "\n",
        "  def _choose_activation(self, X):\n",
        "\n",
        "    if self.activation == \"sigmoid\":\n",
        "      X = Activations.sigmoid(X)\n",
        "      self.activation_derivative = Activations.sigmoid_derivative\n",
        "    \n",
        "    elif self.activation == \"linear\":\n",
        "      X = Activations.linear(X)\n",
        "    \n",
        "    elif self.activation == \"relu\":\n",
        "      X = Activations.relu(X)\n",
        "      self.activation_derivative = Activations.relu_derivative\n",
        "\n",
        "    elif self.activation == \"leaky_relu\":\n",
        "      X = Activations.leaky_relu(X)\n",
        "      self.activation_derivative = Activations.leaky_relu_derivative\n",
        "\n",
        "    elif self.activation == \"tanh\":\n",
        "      X = Activations.tanh(X)\n",
        "      self.activation_derivative = Activations.tanh_derivative\n",
        "\n",
        "    return X\n",
        "    \n",
        "  def _bind_to(self, layer):\n",
        "\n",
        "    self.input_shape = (layer.units, 1)\n",
        "    self.__init_weights()\n",
        "\n",
        "  def _set_layer_type(self, layer_type):\n",
        "\n",
        "    self.layer_type = layer_type\n",
        "\n",
        "  def _set_learning_rate(self, learning_rate):\n",
        "    \n",
        "    self.learning_rate = learning_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rD9tp5FcdwM",
        "colab_type": "text"
      },
      "source": [
        "# **Model class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKi5ojI9zXl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel:\n",
        "  \n",
        "  def __init__(self, learning_rate=0.01):\n",
        "\n",
        "    self.layers = list()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.history = dict()\n",
        "\n",
        "\n",
        "  def add_layer(self, layer):\n",
        "\n",
        "    if len(self.layers) == 0:\n",
        "\n",
        "      self.layers.append(layer)\n",
        "      self.layers[0]._set_layer_type(\"output_layer\")\n",
        "\n",
        "    else:\n",
        "\n",
        "      layer._bind_to(self.layers[-1])\n",
        "      self.layers[-1].next_layer = layer\n",
        "      self.layers.append(layer)\n",
        "      \n",
        "\n",
        "      n = len(self.layers)\n",
        "      last_layer_i = n - 1\n",
        "      before_last_i = n - 2\n",
        "\n",
        "      self.layers[last_layer_i]._set_layer_type(\"output_layer\")\n",
        "      self.layers[before_last_i]._set_layer_type(\"hidden_layer\")\n",
        "\n",
        "    self.layers[-1]._set_learning_rate(self.learning_rate)\n",
        "\n",
        "\n",
        "  def fit(self, X, Y, epochs, verbose=True):\n",
        "\n",
        "    self.history[\"loss\"] = []\n",
        "    m = len(Y)\n",
        "\n",
        "    for i in range(epochs):\n",
        "\n",
        "      if verbose:\n",
        "        print(\"Epoch {}\\n\".format(i+1))\n",
        "  \n",
        "      current_output = X\n",
        "      for j in self.layers:\n",
        "\n",
        "        current_output = j._forward_prop(current_output)\n",
        "      \n",
        "      for j in reversed(range(len(self.layers))):\n",
        "\n",
        "        self.layers[j]._backward_prop(Y)\n",
        "      \n",
        "      logprobs = np.multiply(np.log(current_output.flatten()), Y) + np.multiply(np.log(1-current_output.flatten()), (1-Y))\n",
        "      cost = - np.sum(logprobs) / m\n",
        "      \n",
        "      self.history[\"loss\"].append(cost)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "\n",
        "    current_output = X\n",
        "    for i in self.layers:\n",
        "\n",
        "      current_output = i._forward_prop(current_output)\n",
        "    \n",
        "    return current_output\n",
        "\n",
        "  \n",
        "  def print_layers(self,):\n",
        "    print(\"\\n****************************\\n\")\n",
        "\n",
        "    for i, v in enumerate(self.layers):\n",
        "      print(\"Layer Index: {}\\nLayer Type: {}\\nUnits: {}\\nActivation: {}\\n\"\n",
        "      .format(i, v.layer_type, v.units, v.activation, v.input_size))\n",
        "    \n",
        "    print(\"****************************\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niVW_wLVQ1nj",
        "colab_type": "code",
        "outputId": "a3f20cbf-9298-4e59-a62f-de5a01a2017b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\n",
        "# X and Y are dummy datas which represent the XOR operation.\n",
        "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]]).T\n",
        "Y = np.array([0, 1, 1, 0])\n",
        "print(X.shape)\n",
        "# get the current time\n",
        "past = time.time()\n",
        "\n",
        "# create the model with learning_rate as a parameter\n",
        "model = MyModel(learning_rate=0.1)\n",
        "\n",
        "# create layers\n",
        "layer_1 = Layer(units=4, input_shape=(2, 1), activation=\"tanh\")\n",
        "layer_2 = Layer(units=1, activation=\"sigmoid\")\n",
        "\n",
        "# add layers to the model\n",
        "model.add_layer(layer_1)\n",
        "model.add_layer(layer_2)\n",
        "\n",
        "# fit the data to the model\n",
        "model.fit(X, Y, 2000, verbose=False)\n",
        "\n",
        "# get prediction after fitting the data\n",
        "# use same data as we used in fitting process\n",
        "predictions = model.predict(X)\n",
        "\n",
        "# calculate the accuracy percentage of the predictions\n",
        "accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
        "\n",
        "print(\"Results after fitting:\\n\", after_fit)\n",
        "print(\"\\nAccuracy: {}%\".format(accuracy))\n",
        "print(\"\\nTime passed: {} seconds\".format(time.time() - past))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 4)\n",
            "Results after fitting:\n",
            " [[0.03386414]\n",
            " [0.97744239]\n",
            " [0.97891174]\n",
            " [0.00428964]]\n",
            "\n",
            "Accuracy: 98.46641312244603%\n",
            "\n",
            "Time passed: 0.16193914413452148 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIPH6QVKREPG",
        "colab_type": "code",
        "outputId": "eb43c426-8229-44dc-e03f-da3d0036df23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(model.history[\"loss\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fee4a684438>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MrC_96GCF82",
        "colab_type": "code",
        "outputId": "ef84d1b4-67a5-42d7-e8b6-d02f2fbbc504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# same dummy data as before we used\n",
        "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]]).T\n",
        "Y = np.array([0, 1, 1, 0])\n",
        "\n",
        "# number of units in a hidden layer\n",
        "unit_numbers = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
        "\n",
        "# try each number of hidden units in the for loop and\n",
        "# print the accuracy for each one\n",
        "# epoch is defined as 1000\n",
        "for n_hidden_units in unit_numbers:\n",
        "\n",
        "  model = MyModel(0.1)\n",
        "\n",
        "  layer_1 = Layer(units=n_hidden_units, input_shape=(2, 1), activation=\"tanh\")\n",
        "  layer_2 = Layer(units=1, activation=\"sigmoid\")\n",
        "\n",
        "  model.add_layer(layer_1)\n",
        "  model.add_layer(layer_2)\n",
        "\n",
        "  model.fit(X, Y, epochs=1000, verbose=False)\n",
        "\n",
        "  predictions = model.predict(X)\n",
        "\n",
        "  accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
        "\n",
        "  print(\"Accuracy for {} hidden units: {}%\".format(n_hidden_units, accuracy))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 1 hidden units: 66.16058159748553%\n",
            "Accuracy for 2 hidden units: 97.02922579728171%\n",
            "Accuracy for 3 hidden units: 96.5205345303777%\n",
            "Accuracy for 4 hidden units: 96.63291050169838%\n",
            "Accuracy for 5 hidden units: 96.49812711822749%\n",
            "Accuracy for 10 hidden units: 96.105484108208%\n",
            "Accuracy for 20 hidden units: 96.60991405851951%\n",
            "Accuracy for 50 hidden units: 96.85797035549724%\n",
            "Accuracy for 100 hidden units: 98.68565859730916%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia7vsOBsjWfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}